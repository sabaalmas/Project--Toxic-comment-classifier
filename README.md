# Technocolabs
Toxic Comment Classifier


The complete project has 5 seperate models- Toxic, Severe Toxic, Obscene, Insult and Identity threat
Due to lagre file size issue, only 2 could be uploaded.
The following are the files:

3 images: Welcome Page, Input, Output
1 .py file: toxic_app.py
1 notebook: Final

